# ğŸŒ First Data Project - Pipeline ETL MÃ©tÃ©o

> **Un pipeline ETL complet pour extraire, transformer et charger les donnÃ©es mÃ©tÃ©orologiques de 5 villes du monde dans une base de donnÃ©es MySQL**

---

## ğŸ“‹ Table des matiÃ¨res

- [ğŸ¯ Vue d'ensemble](#-vue-densemble)
- [âœ¨ FonctionnalitÃ©s](#-fonctionnalitÃ©s)
- [ğŸ—ï¸ Architecture](#-architecture)
- [ğŸ“¦ Installation](#-installation)
- [ğŸš€ Utilisation](#-utilisation)
- [ğŸ“‚ Structure du projet](#-structure-du-projet)
- [ğŸ”„ Pipeline ETL](#-pipeline-etl)
- [ğŸ› ï¸ Configuration](#-configuration)
- [ğŸ“Š DonnÃ©es](#-donnÃ©es)
- [ğŸ› DÃ©pannage](#-dÃ©pannage)
- [ğŸ“ Licence](#-licence)

---

## ğŸ¯ Vue d'ensemble

Ce projet implÃ©mente un **pipeline ETL (Extract, Transform, Load)** automatisÃ© pour :

âœ… **Extraire** les donnÃ©es mÃ©tÃ©orologiques en temps rÃ©el depuis l'API OpenWeatherMap
âœ… **Transformer** les donnÃ©es brutes pour les nettoyer et normaliser
âœ… **Charger** les donnÃ©es transformÃ©es dans une base de donnÃ©es MySQL

Le pipeline gÃ¨re gracieusement les erreurs, sauvegarde localement en CSV/JSON, et inclut un systÃ¨me de logging complet.

---

## âœ¨ FonctionnalitÃ©s

| FonctionnalitÃ© | Description |
|---|---|
| ğŸŒ **Extraction API** | RÃ©cupÃ¨re les donnÃ©es mÃ©tÃ©orologiques de 5 villes majeures via OpenWeatherMap |
| ğŸ§¹ **Nettoyage des donnÃ©es** | Supprime les doublons, traite les valeurs manquantes |
| ğŸ“Š **Transformation** | Normalise les unitÃ©s de tempÃ©rature, structure les donnÃ©es |
| ğŸ’¾ **Stockage multi-format** | Sauvegarde en CSV, JSON et MySQL |
| ğŸ“ **Logging dÃ©taillÃ©** | Enregistre toutes les Ã©tapes du pipeline |
| âš¡ **Gestion d'erreurs** | Fallback gracieux si la base de donnÃ©es est indisponible |
| ğŸ” **Configuration sÃ©curisÃ©e** | CrÃ©dentiels stockÃ©s dans les variables d'environnement |

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  MAIN.PY - Orchestrateur            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                              â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  EXTRACT      â”‚            â”‚   TRANSFORM       â”‚
    â”‚  - API Call   â”‚            â”‚   - Nettoyage     â”‚
    â”‚  - JSON Save  â”‚            â”‚   - Normalisation â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                             â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚    LOAD      â”‚
                    â”‚  - MySQL DB  â”‚
                    â”‚  - CSV/JSON  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ Installation

### ğŸ“‹ PrÃ©requis

- **Python** 3.8+
- **MySQL Server** 5.7+ (optionnel pour la sauvegarde locale)
- **pip** (gestionnaire de paquets Python)

### ğŸ”§ Ã‰tape 1 : Cloner le repository

```bash
git clone <votre-repo>
cd First_Data_Project
```

### ğŸ”§ Ã‰tape 2 : CrÃ©er un environnement virtuel

```bash
# Sur Windows
python -m venv venv
venv\Scripts\activate

# Sur macOS/Linux
python3 -m venv venv
source venv/bin/activate
```

### ğŸ”§ Ã‰tape 3 : Installer les dÃ©pendances

```bash
pip install -r requirements.txt
```

### ğŸ”§ Ã‰tape 4 : Configurer les variables d'environnement

CrÃ©ez un fichier `.env` Ã  la racine du projet (optionnel) :

```env
DB_USER=davy
DB_PASSWORD=password123
DB_HOST=localhost
DB_NAME=First_Data
API_KEY=21df4d73e5dc83ea09d6f0ed3148d2bc
```

### ğŸ”§ Ã‰tape 5 : Configurer MySQL (optionnel)

```bash
# VÃ©rifier le statut de MySQL
sudo systemctl status mysql

# DÃ©marrer MySQL si nÃ©cessaire
sudo systemctl start mysql

# CrÃ©er la base de donnÃ©es
mysql -u root -p
> CREATE DATABASE First_Data;
```

---

## ğŸš€ Utilisation

### â–¶ï¸ ExÃ©cuter le pipeline complet

```bash
python main.py
```

**RÃ©sultat attendu :**
```
2026-02-04 23:31:25,222 - INFO - Logger configured.
[EXTRACT] Starting extraction...
2026-02-04 23:32:14,137 - INFO - Data for Ouagadougou: {...}
...
2026-02-04 23:32:15,357 - INFO - [TRANSFORM] Cleaned data saved to clean.csv
2026-02-04 23:32:15,662 - INFO - Data loaded successfully
```

### â–¶ï¸ ExÃ©cuter uniquement l'extraction

```bash
python -m etl.Extract
```

### â–¶ï¸ ExÃ©cuter uniquement la transformation

```bash
python -m etl.Transform
```

### â–¶ï¸ ExÃ©cuter uniquement le chargement

```bash
python -m etl.Load
```

---

## ğŸ“‚ Structure du projet

```
First_Data_Project/
â”‚
â”œâ”€â”€ ğŸ“„ main.py                 # Point d'entrÃ©e principal
â”œâ”€â”€ ğŸ“„ requirements.txt         # DÃ©pendances du projet
â”œâ”€â”€ ğŸ“„ README.md               # Cette documentation
â”‚
â”œâ”€â”€ ğŸ“ config/                 # Configuration
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ logger.py              # Configuration du logging
â”‚
â”œâ”€â”€ ğŸ“ etl/                    # Pipeline ETL
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ Extract.py             # Ã‰tape d'extraction (API)
â”‚   â”œâ”€â”€ Transform.py           # Ã‰tape de transformation (nettoyage)
â”‚   â””â”€â”€ Load.py                # Ã‰tape de chargement (BD)
â”‚
â”œâ”€â”€ ğŸ“ data/                   # DonnÃ©es brutes (JSON)
â”‚   â”œâ”€â”€ Ouagadougou.json
â”‚   â”œâ”€â”€ New York.json
â”‚   â”œâ”€â”€ Londres.json
â”‚   â”œâ”€â”€ Tokyo.json
â”‚   â””â”€â”€ Sydney.json
â”‚
â”œâ”€â”€ ğŸ“ data_clean/             # DonnÃ©es transformÃ©es
â”‚   â”œâ”€â”€ clean.csv              # DonnÃ©es nettoyÃ©es (CSV)
â”‚   â”œâ”€â”€ loaded_data.csv        # DonnÃ©es chargÃ©es (CSV)
â”‚   â”œâ”€â”€ loaded_data.json       # DonnÃ©es chargÃ©es (JSON)
â”‚   â””â”€â”€ requÃ¨tes.sql           # RequÃªtes SQL d'exemple
â”‚
â””â”€â”€ ğŸ“ logs/                   # Fichiers de log
    â””â”€â”€ app.log                # Log du pipeline
```

---

## ğŸ”„ Pipeline ETL

### **1ï¸âƒ£ Phase EXTRACT - Extraction des donnÃ©es**

**Fichier :** [etl/Extract.py](etl/Extract.py)

ğŸ“¡ **RÃ©cupÃ¨re les donnÃ©es mÃ©tÃ©orologiques** depuis l'API OpenWeatherMap pour 5 villes :
- ğŸŒ Ouagadougou (Burkina Faso)
- ğŸŒƒ New York (USA)
- ğŸ´ó §ó ¢ó ¥ó ®ó §ó ¿ Londres (UK)
- ğŸ—¾ Tokyo (Japon)
- ğŸ¦˜ Sydney (Australie)

**DonnÃ©es extraites :**
```json
{
  "name": "Ouagadougou",
  "sys": {"country": "BF"},
  "main": {
    "temp": 300.22,
    "temp_min": 300.22,
    "temp_max": 300.22,
    "humidity": 17
  },
  "weather": [{"description": "clear sky"}],
  "wind": {"speed": 2.57}
}
```

**Actions :**
- âœ… Appel API avec gestion des erreurs
- âœ… Sauvegarde en fichiers JSON
- âœ… Logging dÃ©taillÃ© de chaque Ã©tape

---

### **2ï¸âƒ£ Phase TRANSFORM - Transformation des donnÃ©es**

**Fichier :** [etl/Transform.py](etl/Transform.py)

ğŸ§¹ **Nettoie et normalise** les donnÃ©es brutes :

**Processus :**
1. **Chargement** des fichiers JSON depuis `/data`
2. **Extraction** des champs pertinents
3. **Suppression des doublons** avec `drop_duplicates()`
4. **Gestion des valeurs manquantes** avec `dropna()`
5. **Conversion des types** en numÃ©riques
6. **Ajout du timestamp** (date de scrape)
7. **Sauvegarde** en CSV pour vÃ©rification

**DonnÃ©es transformÃ©es :**
```
     ville     pays   temp  temp_min  temp_max  humidite           description  vitesse_vent         scrape_date
0  Ouagadougou   BF  300.22    300.22    300.22        17           clear sky           2.57  2026-02-04 23:32:15
1    New York   US  273.53    271.46    274.13        36           clear sky           4.12  2026-02-04 23:32:15
2     London   GB  281.19    280.32    281.82        84      broken clouds           8.23  2026-02-04 23:32:15
3      Tokyo   JP  278.48    276.82    279.94        56        few clouds           2.57  2026-02-04 23:32:15
4     Sydney   AU  301.61    300.76    303.12        58           clear sky           4.12  2026-02-04 23:32:15
```

**AmÃ©liorations appliquÃ©es :**
- âœ… Suppression des lignes avec tempÃ©rature ou humiditÃ© manquante
- âœ… Normalisation des types de donnÃ©es
- âœ… Ajout d'un timestamp universel
- âœ… Validation des donnÃ©es

---

### **3ï¸âƒ£ Phase LOAD - Chargement des donnÃ©es**

**Fichier :** [etl/Load.py](etl/Load.py)

ğŸ’¾ **Charge les donnÃ©es transformÃ©es** dans la base de donnÃ©es MySQL

**Architecture BD :**
```sql
CREATE TABLE weather_data (
  id INT PRIMARY KEY AUTO_INCREMENT,
  ville VARCHAR(50) NOT NULL,
  pays VARCHAR(5) NOT NULL,
  temp FLOAT,
  temp_min FLOAT,
  temp_max FLOAT,
  humidite INT,
  description VARCHAR(100),
  vitesse_vent FLOAT,
  scrape_date DATETIME NOT NULL
);
```

**Actions :**
- âœ… CrÃ©ation de la table si elle n'existe pas
- âœ… Insertion des donnÃ©es avec mode `APPEND`
- âœ… Sauvegarde CSV et JSON en secours
- âœ… Gestion des erreurs de connexion

**Fallback :** Si MySQL est indisponible, les donnÃ©es sont sauvegardÃ©es localement en CSV/JSON

---

## ğŸ› ï¸ Configuration

### ğŸ“ Configuration du logger

**Fichier :** [config/logger.py](config/logger.py)

```python
import logging

def setup_logger():
    logger = logging.getLogger("etl_pipeline")
    handler = logging.StreamHandler()
    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
    handler.setFormatter(formatter)
    logger.addHandler(handler)
    logger.setLevel(logging.INFO)
    return logger
```

### ğŸ“‹ DÃ©pendances

**Fichier :** [requirements.txt](requirements.txt)

```
pandas==3.0.0
numpy==2.4.2
requests==2.32.5
sqlalchemy==2.0.46
pymysql==1.1.2
beautifulsoup4==4.14.3
pyyaml==6.0.3
```

Installation :
```bash
pip install -r requirements.txt
```

---

## ğŸ“Š DonnÃ©es

### ğŸ—‚ï¸ Fichiers de donnÃ©es

| Fichier | Format | Description |
|---------|--------|-------------|
| `data/*.json` | JSON | DonnÃ©es brutes de l'API |
| `data_clean/clean.csv` | CSV | DonnÃ©es nettoyÃ©es |
| `data_clean/loaded_data.csv` | CSV | DonnÃ©es chargÃ©es dans BD |
| `data_clean/loaded_data.json` | JSON Lines | DonnÃ©es chargÃ©es en JSON |

### ğŸ“ˆ Statistiques attendues

- **Villes extraites :** 5
- **Champs par ville :** 9 (ville, pays, temp, temp_min, temp_max, humidite, description, vitesse_vent, scrape_date)
- **Lignes totales :** 5 (une par ville)
- **Format donnÃ©es :** Kelvin (API) â†’ Converti pour stockage

---

## ğŸ› DÃ©pannage

### âŒ Erreur : `ModuleNotFoundError: No module named 'pymysql'`

**Solution :**
```bash
pip install pymysql
```

### âŒ Erreur : `Connection refused` pour MySQL

**VÃ©rifier le service MySQL :**
```bash
# Status
sudo systemctl status mysql

# DÃ©marrer
sudo systemctl start mysql
```

### âŒ Erreur : `Access denied for user 'davy'`

**VÃ©rifier les crÃ©dentiels :**
1. Ouvrir [etl/Load.py](etl/Load.py)
2. VÃ©rifier la chaÃ®ne de connexion
3. S'assurer que l'utilisateur MySQL existe :
```sql
CREATE USER 'davy'@'localhost' IDENTIFIED BY 'password123';
GRANT ALL PRIVILEGES ON First_Data.* TO 'davy'@'localhost';
FLUSH PRIVILEGES;
```

### âŒ Erreur : `Request timeout` lors de l'extraction

**Solution :**
- VÃ©rifier la connexion Internet
- VÃ©rifier la clÃ© API OpenWeatherMap
- Relancer le pipeline

### âš ï¸ Avertissement : `Database driver not available`

**Signification :** `pymysql` n'est pas installÃ©, les donnÃ©es sont sauvegardÃ©es localement
**Solution :** `pip install pymysql`

---

## ğŸ“Š RÃ©sultat d'exÃ©cution complet

```
2026-02-04 23:31:25,222 - INFO - Logger configured.
[EXTRACT] Starting extraction...
2026-02-04 23:32:14,137 - INFO - Data for Ouagadougou: {...}
2026-02-04 23:32:14,450 - INFO - Data for New York: {...}
2026-02-04 23:32:14,730 - INFO - Data for Londres: {...}
2026-02-04 23:32:15,012 - INFO - Data for Tokyo: {...}
2026-02-04 23:32:15,314 - INFO - Data for Sydney: {...}
2026-02-04 23:32:15,314 - INFO - [TRANSFORM] Starting transformation
2026-02-04 23:32:15,324 - INFO - [TRANSFORM] DataFrame created with shape (5, 8)
2026-02-04 23:32:15,341 - INFO - [TRANSFORM] Rows before: 5 â†’ after: 5
2026-02-04 23:32:15,357 - INFO - [TRANSFORM] Cleaned data saved to clean.csv
2026-02-04 23:32:15,662 - INFO - Data loaded successfully
```

---

## ğŸ“– Exemple de requÃªte SQL

```sql
-- TempÃ©rature moyenne par pays
SELECT pays, AVG(temp) as temp_moyenne
FROM weather_data
GROUP BY pays
ORDER BY temp_moyenne DESC;

-- Villes les plus humides
SELECT ville, humidite
FROM weather_data
ORDER BY humidite DESC
LIMIT 3;

-- DerniÃ¨res donnÃ©es (plus rÃ©centes)
SELECT * FROM weather_data
ORDER BY scrape_date DESC
LIMIT 10;
```

---

## ğŸ¤ Contribution

Les contributions sont bienvenues ! Pour proposer une amÃ©lioration :

1. ğŸ´ Fork le projet
2. ğŸŒ¿ CrÃ©er une branche (`git checkout -b feature/AmazingFeature`)
3. ğŸ“ Commit les changements (`git commit -m 'Add AmazingFeature'`)
4. ğŸ“¤ Push vers la branche (`git push origin feature/AmazingFeature`)
5. ğŸ”„ Ouvrir une Pull Request

---

## ğŸ“ Licence

Ce projet est sous licence **MIT**. Voir le fichier `LICENSE` pour plus de dÃ©tails.

---

## ğŸ‘¤ Auteur

**Davy** - [GitHub](https://github.com) | [Email](mailto:davy@example.com)

---

## ğŸ™ Remerciements

- ğŸŒ [OpenWeatherMap API](https://openweathermap.org/api)
- ğŸ [Pandas Documentation](https://pandas.pydata.org/)
- ğŸ—„ï¸ [SQLAlchemy ORM](https://www.sqlalchemy.org/)

---

## ğŸ“ Support

Pour toute question ou problÃ¨me, veuillez :
- ğŸ“ Ouvrir une **Issue** sur GitHub
- ğŸ’¬ Me contacter directement

---

<div align="center">

### â­ Si ce projet vous a aidÃ©, n'hÃ©sitez pas Ã  lui donner une star !

**DerniÃ¨re mise Ã  jour :** 4 fÃ©vrier 2026

</div>
